Summary of Data cleaning:
To begin, the following stages fo data cleaning were followed:
1. Opening and combining the various datasets into one
2. Converting the data to a dataframe, dropping patient data and 'junk' columns, and reorganizing patients by corrected id
3. Removing patient column data that does not satisfy 80% or 90% filled, then removing patient row data with the same criteria
4. Convert remaining absent values to nan's, convert dataframe to numeric, and then describe the dataset (mean, std, quartiles)
4a. Look for the presence of outliers and remove
5. Replace all heart disease values as either present (1) or not present(0)
6. Replace non-categorical/non-binary data values as numeric for evaluation and export as csv
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3701793/

Further steps:

Although several categories qualified due to data completeness, several were retroactively removed before calculating data completeness
as they were either: 1. Unhelpful or 2. Not descriptive and therefore introduce uncertainty of meaning or interpretation.

1. Unhelpful:
'social_security',
'card_cath_month',
'card_cath_year',
'card_cath_day',
'junk',
'exer_ecg_month',
'exer_ecg_day', 
'exer_ecg_year',

*****************Consider adding these variables back in after testing to see if accuracy improves or declines
'digitalis_ecg',
'prop_ecg', 
'nitr_ecg',
'ccb_ecg', 
'diur_ecg', 

2. Uncertain without further descriptive information:
'lvx1', 
'lvx2', 
'lvx3', 
'lvx4', 
'lvf'
